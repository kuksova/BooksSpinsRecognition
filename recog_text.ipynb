{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dc83ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('D:/Sveta/BooksOCR/PaddleOCR/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "333cd60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D is HDD\n",
      " Volume Serial Number is 4224-0798\n",
      "\n",
      " Directory of D:\\Sveta\\BooksOCR\\PaddleOCR\n",
      "\n",
      "07/21/2023  03:24 PM    <DIR>          .\n",
      "07/21/2023  04:50 PM    <DIR>          ..\n",
      "07/21/2023  03:20 PM               353 .clang_format.hook\n",
      "07/21/2023  03:20 PM    <DIR>          .github\n",
      "07/21/2023  03:20 PM               469 .gitignore\n",
      "07/21/2023  03:20 PM             1,017 .pre-commit-config.yaml\n",
      "07/21/2023  03:20 PM                48 .style.yapf\n",
      "07/21/2023  03:20 PM    <DIR>          applications\n",
      "07/21/2023  03:20 PM    <DIR>          benchmark\n",
      "07/21/2023  03:20 PM    <DIR>          configs\n",
      "07/21/2023  03:20 PM    <DIR>          deploy\n",
      "07/21/2023  03:20 PM    <DIR>          doc\n",
      "07/21/2023  03:20 PM            11,438 LICENSE\n",
      "07/21/2023  03:20 PM               294 MANIFEST.in\n",
      "07/21/2023  03:31 PM    <DIR>          model\n",
      "07/21/2023  03:20 PM            31,653 paddleocr.py\n",
      "07/21/2023  03:20 PM    <DIR>          ppocr\n",
      "07/21/2023  03:20 PM    <DIR>          PPOCRLabel\n",
      "07/21/2023  03:21 PM    <DIR>          ppstructure\n",
      "07/21/2023  03:20 PM            17,878 README.md\n",
      "07/21/2023  03:20 PM            17,547 README_ch.md\n",
      "07/21/2023  03:20 PM               209 requirements.txt\n",
      "07/21/2023  03:20 PM             2,601 setup.py\n",
      "07/21/2023  03:20 PM    <DIR>          StyleText\n",
      "07/21/2023  03:21 PM    <DIR>          test_tipc\n",
      "07/21/2023  03:21 PM    <DIR>          tools\n",
      "07/21/2023  03:20 PM               181 train.sh\n",
      "07/21/2023  03:20 PM               865 __init__.py\n",
      "              13 File(s)         84,553 bytes\n",
      "              15 Dir(s)  155,044,429,824 bytes free\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d53ff47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shapely\n",
      "  Downloading shapely-2.0.1-cp310-cp310-win_amd64.whl (1.4 MB)\n",
      "     ---------------------------------------- 1.4/1.4 MB 14.4 MB/s eta 0:00:00\n",
      "Collecting scikit-image\n",
      "  Downloading scikit_image-0.21.0-cp310-cp310-win_amd64.whl (22.8 MB)\n",
      "     --------------------------------------- 22.8/22.8 MB 20.4 MB/s eta 0:00:00\n",
      "Collecting imgaug\n",
      "  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
      "     ------------------------------------- 948.0/948.0 kB 20.4 MB/s eta 0:00:00\n",
      "Collecting pyclipper\n",
      "  Downloading pyclipper-1.3.0.post4-cp310-cp310-win_amd64.whl (94 kB)\n",
      "     ---------------------------------------- 94.5/94.5 kB ? eta 0:00:00\n",
      "Collecting lmdb\n",
      "  Downloading lmdb-1.4.1-cp310-cp310-win_amd64.whl (100 kB)\n",
      "     -------------------------------------- 100.1/100.1 kB 5.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in d:\\programs\\lib\\site-packages (from -r requirements.txt (line 6)) (4.64.1)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.25.1-cp310-cp310-win_amd64.whl (15.0 MB)\n",
      "     --------------------------------------- 15.0/15.0 MB 23.3 MB/s eta 0:00:00\n",
      "Collecting visualdl\n",
      "  Downloading visualdl-2.5.3-py3-none-any.whl (6.3 MB)\n",
      "     ---------------------------------------- 6.3/6.3 MB 22.5 MB/s eta 0:00:00\n",
      "Collecting rapidfuzz\n",
      "  Downloading rapidfuzz-3.1.2-cp310-cp310-win_amd64.whl (1.8 MB)\n",
      "     ---------------------------------------- 1.8/1.8 MB 19.3 MB/s eta 0:00:00\n",
      "Collecting opencv-python==4.6.0.66\n",
      "  Downloading opencv_python-4.6.0.66-cp36-abi3-win_amd64.whl (35.6 MB)\n",
      "     --------------------------------------- 35.6/35.6 MB 20.4 MB/s eta 0:00:00\n",
      "Collecting opencv-contrib-python==4.6.0.66\n",
      "  Downloading opencv_contrib_python-4.6.0.66-cp36-abi3-win_amd64.whl (42.5 MB)\n",
      "     --------------------------------------- 42.5/42.5 MB 15.2 MB/s eta 0:00:00\n",
      "Collecting cython\n",
      "  Downloading Cython-3.0.0-cp310-cp310-win_amd64.whl (2.8 MB)\n",
      "     ---------------------------------------- 2.8/2.8 MB 11.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: lxml in d:\\programs\\lib\\site-packages (from -r requirements.txt (line 13)) (4.9.1)\n",
      "Collecting premailer\n",
      "  Downloading premailer-3.10.0-py2.py3-none-any.whl (19 kB)\n",
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\n",
      "     ------------------------------------- 250.0/250.0 kB 15.0 MB/s eta 0:00:00\n",
      "Collecting attrdict\n",
      "  Downloading attrdict-2.0.1-py2.py3-none-any.whl (9.9 kB)\n",
      "Collecting Polygon3\n",
      "  Downloading Polygon3-3.0.9.1.tar.gz (39 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting lanms-neo==1.0.2\n",
      "  Downloading lanms_neo-1.0.2.tar.gz (39 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting PyMuPDF<1.21.0\n",
      "  Downloading PyMuPDF-1.20.2-cp310-cp310-win_amd64.whl (6.6 MB)\n",
      "     ---------------------------------------- 6.6/6.6 MB 17.5 MB/s eta 0:00:00\n",
      "Collecting tifffile>=2022.8.12\n",
      "  Downloading tifffile-2023.7.18-py3-none-any.whl (221 kB)\n",
      "     ------------------------------------- 221.4/221.4 kB 13.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=21 in d:\\programs\\lib\\site-packages (from scikit-image->-r requirements.txt (line 2)) (22.0)\n",
      "Collecting imageio>=2.27\n",
      "  Downloading imageio-2.31.1-py3-none-any.whl (313 kB)\n",
      "     ------------------------------------- 313.2/313.2 kB 18.9 MB/s eta 0:00:00\n",
      "Collecting scipy>=1.8\n",
      "  Downloading scipy-1.11.1-cp310-cp310-win_amd64.whl (44.0 MB)\n",
      "     --------------------------------------- 44.0/44.0 MB 15.6 MB/s eta 0:00:00\n",
      "Collecting lazy_loader>=0.2\n",
      "  Downloading lazy_loader-0.3-py3-none-any.whl (9.1 kB)\n",
      "Collecting networkx>=2.8\n",
      "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 18.9 MB/s eta 0:00:00\n",
      "Collecting pillow>=9.0.1\n",
      "  Downloading Pillow-10.0.0-cp310-cp310-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 2.5/2.5 MB 13.4 MB/s eta 0:00:00\n",
      "Collecting PyWavelets>=1.1.1\n",
      "  Downloading PyWavelets-1.4.1-cp310-cp310-win_amd64.whl (4.2 MB)\n",
      "     ---------------------------------------- 4.2/4.2 MB 17.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six in d:\\programs\\lib\\site-packages (from imgaug->-r requirements.txt (line 3)) (1.16.0)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.7.2-cp310-cp310-win_amd64.whl (7.5 MB)\n",
      "     ---------------------------------------- 7.5/7.5 MB 17.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in d:\\programs\\lib\\site-packages (from tqdm->-r requirements.txt (line 6)) (0.4.5)\n",
      "Collecting bce-python-sdk\n",
      "  Downloading bce_python_sdk-0.8.87-py3-none-any.whl (231 kB)\n",
      "     ------------------------------------- 231.3/231.3 kB 13.8 MB/s eta 0:00:00\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.0.3-cp310-cp310-win_amd64.whl (10.7 MB)\n",
      "     --------------------------------------- 10.7/10.7 MB 21.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in d:\\programs\\lib\\site-packages (from visualdl->-r requirements.txt (line 8)) (2.28.1)\n",
      "Requirement already satisfied: psutil in d:\\programs\\lib\\site-packages (from visualdl->-r requirements.txt (line 8)) (5.9.0)\n",
      "Collecting Flask-Babel>=3.0.0\n",
      "  Downloading flask_babel-3.1.0-py3-none-any.whl (9.6 kB)\n",
      "Collecting protobuf>=3.20.0\n",
      "  Downloading protobuf-4.23.4-cp310-abi3-win_amd64.whl (422 kB)\n",
      "     ------------------------------------- 422.5/422.5 kB 13.3 MB/s eta 0:00:00\n",
      "Collecting flask>=1.1.1\n",
      "  Downloading Flask-2.3.2-py3-none-any.whl (96 kB)\n",
      "     ---------------------------------------- 96.9/96.9 kB ? eta 0:00:00\n",
      "Collecting rarfile\n",
      "  Downloading rarfile-4.0-py3-none-any.whl (28 kB)\n",
      "Collecting cachetools\n",
      "  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Collecting cssutils\n",
      "  Downloading cssutils-2.7.1-py3-none-any.whl (399 kB)\n",
      "     ------------------------------------- 399.7/399.7 kB 24.3 MB/s eta 0:00:00\n",
      "Collecting cssselect\n",
      "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting et-xmlfile\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in d:\\programs\\lib\\site-packages (from flask>=1.1.1->visualdl->-r requirements.txt (line 8)) (3.1.2)\n",
      "Collecting blinker>=1.6.2\n",
      "  Downloading blinker-1.6.2-py3-none-any.whl (13 kB)\n",
      "Collecting itsdangerous>=2.1.2\n",
      "  Using cached itsdangerous-2.1.2-py3-none-any.whl (15 kB)\n",
      "Collecting click>=8.1.3\n",
      "  Downloading click-8.1.6-py3-none-any.whl (97 kB)\n",
      "     ---------------------------------------- 97.9/97.9 kB 5.8 MB/s eta 0:00:00\n",
      "Collecting Werkzeug>=2.3.3\n",
      "  Downloading Werkzeug-2.3.6-py3-none-any.whl (242 kB)\n",
      "     ------------------------------------- 242.5/242.5 kB 14.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pytz>=2022.7 in d:\\programs\\lib\\site-packages (from Flask-Babel>=3.0.0->visualdl->-r requirements.txt (line 8)) (2022.7)\n",
      "Collecting Babel>=2.12\n",
      "  Downloading Babel-2.12.1-py3-none-any.whl (10.1 MB)\n",
      "     --------------------------------------- 10.1/10.1 MB 22.2 MB/s eta 0:00:00\n",
      "Collecting future>=0.6.0\n",
      "  Downloading future-0.18.3.tar.gz (840 kB)\n",
      "     ------------------------------------- 840.9/840.9 kB 26.8 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pycryptodome>=3.8.0\n",
      "  Downloading pycryptodome-3.18.0-cp35-abi3-win_amd64.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 22.1 MB/s eta 0:00:00\n",
      "Collecting pyparsing<3.1,>=2.3.1\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\programs\\lib\\site-packages (from matplotlib->imgaug->-r requirements.txt (line 3)) (2.8.2)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.41.1-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "     ---------------------------------------- 2.1/2.1 MB 19.2 MB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.4-cp310-cp310-win_amd64.whl (55 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.1.0-cp310-cp310-win_amd64.whl (470 kB)\n",
      "     ------------------------------------- 470.4/470.4 kB 30.7 MB/s eta 0:00:00\n",
      "Collecting tzdata>=2022.1\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "     ------------------------------------- 341.8/341.8 kB 22.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\programs\\lib\\site-packages (from requests->visualdl->-r requirements.txt (line 8)) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in d:\\programs\\lib\\site-packages (from requests->visualdl->-r requirements.txt (line 8)) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\programs\\lib\\site-packages (from requests->visualdl->-r requirements.txt (line 8)) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\programs\\lib\\site-packages (from requests->visualdl->-r requirements.txt (line 8)) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\programs\\lib\\site-packages (from Jinja2>=3.1.2->flask>=1.1.1->visualdl->-r requirements.txt (line 8)) (2.1.1)\n",
      "Building wheels for collected packages: lanms-neo, Polygon3, future\n",
      "  Building wheel for lanms-neo (pyproject.toml): started\n",
      "  Building wheel for lanms-neo (pyproject.toml): finished with status 'error'\n",
      "  Building wheel for Polygon3 (setup.py): started\n",
      "  Building wheel for Polygon3 (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for Polygon3\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492025 sha256=947a8f1da0968f78cd4f8c727e2b275033ccc6c06ed33258429b655dc3761fb1\n",
      "  Stored in directory: c:\\users\\oleg\\appdata\\local\\pip\\cache\\wheels\\69\\c0\\ce\\f2a18105d619f21239a048bcc58e98d8ce47ac824e0531f1a0\n",
      "Successfully built future\n",
      "Failed to build lanms-neo Polygon3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Building wheel for lanms-neo (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [10 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-310\n",
      "  creating build\\lib.win-amd64-cpython-310\\lanms\n",
      "  copying lanms\\__init__.py -> build\\lib.win-amd64-cpython-310\\lanms\n",
      "  running build_ext\n",
      "  building 'lanms._C' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for lanms-neo\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py bdist_wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [14 lines of output]\n",
      "  NumPy extension not found - disabling support for it!\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-310\n",
      "  creating build\\lib.win-amd64-cpython-310\\Polygon\n",
      "  copying Polygon\\IO.py -> build\\lib.win-amd64-cpython-310\\Polygon\n",
      "  copying Polygon\\Shapes.py -> build\\lib.win-amd64-cpython-310\\Polygon\n",
      "  copying Polygon\\Utils.py -> build\\lib.win-amd64-cpython-310\\Polygon\n",
      "  copying Polygon\\__init__.py -> build\\lib.win-amd64-cpython-310\\Polygon\n",
      "  running build_ext\n",
      "  building 'Polygon.cPolygon' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for Polygon3\n",
      "ERROR: Could not build wheels for lanms-neo, which is required to install pyproject.toml-based projects\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "595e5c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"D:\\Sveta\\BooksOCR\\PaddleOCR\\tools\\infer_det.py\", line 32, in <module>\n",
      "    import paddle\n",
      "ModuleNotFoundError: No module named 'paddle'\n"
     ]
    }
   ],
   "source": [
    "!python3 D:\\Sveta\\BooksOCR\\PaddleOCR\\tools\\infer_det.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7a7441-5f4e-4e2f-9aab-9666c5b1cc7d",
   "metadata": {},
   "source": [
    "1. Download data without !wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2aa9e18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "\n",
    "def download_mnist(path):\n",
    "    url = \"https://github.com/pytorch/tutorials/raw/main/_static/\"\n",
    "    filename = \"mnist.pkl.gz\"\n",
    "    content = requests.get(url).content # Returns the content of the response, in bytes\n",
    "    \n",
    "    if not path.exists():\n",
    "        content = requests.get(url + filename).content\n",
    "        (path / filename).open(\"wb\").write(content)\n",
    "\n",
    "    return path / filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82565f48-a46f-4c0a-bb78-b1edec92b575",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data\") if Path(\"data\").exists() else Path(\"../data\")\n",
    "path = data_path / \"downloaded\" / \"vector-mnist\"\n",
    "path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "datafile = download_mnist(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "245a1aee-219e-448f-8939-0cf00558bd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = \"../data/downloaded/vector-mnist/mnist.pkl.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0279b067-0927-4298-afbe-6abb2dc3f45a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/downloaded/vector-mnist/mnist.pkl.gz'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e42fc8b-d66b-4de5-8632-e1f562ff3aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mSource:\u001b[0m   \n",
       "\u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;34mr\"\"\"Sends a GET request.\n",
       "\n",
       "    :param url: URL for the new :class:`Request` object.\n",
       "    :param params: (optional) Dictionary, list of tuples or bytes to send\n",
       "        in the query string for the :class:`Request`.\n",
       "    :param \\*\\*kwargs: Optional arguments that ``request`` takes.\n",
       "    :return: :class:`Response <Response>` object\n",
       "    :rtype: requests.Response\n",
       "    \"\"\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"get\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\oleg\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages\\requests\\api.py\n",
       "\u001b[1;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "requests.get??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab5bef5a-0bb8-441b-9d93-105baeb50a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "def read_mnist(path):\n",
    "    with gzip.open(path, \"rb\") as f:\n",
    "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=\"latin-1\")\n",
    "    return x_train, y_train, x_valid, y_valid\n",
    "\n",
    "x_train, y_train, x_valid, y_valid = read_mnist(datafile) \n",
    "# x_train.shape (50000, 784)\n",
    "# y_train.shape (50000,)\n",
    "# x_valid.shape (10000, 784)\n",
    "# img.size (28,28)\n",
    "\n",
    "# Convert to torch tensors\n",
    "x_train, y_train, x_valid, y_valid = map(torch.tensor, (x_train, y_train, x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16236564-6eb7-4177-9d88-f5a6d1400d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 784])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cba45936-96f9-4a41-81c1-655268c5375f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset,TensorDataset, DataLoader,  SubsetRandomSampler\n",
    "from torchvision import transforms\n",
    "\n",
    "#transform_list =  [transforms.Grayscale(1),\n",
    "#                    transforms.Resize((28, 28))]\n",
    "#                    #transforms.ToTensor()]\n",
    "                    #transforms.Normalize((0.5,), (0.5,))]\n",
    "#transform2 = transforms.Compose(transform_list)\n",
    "\n",
    "train_set = TensorDataset(x_train, y_train)\n",
    "val_set = TensorDataset(x_valid, y_valid)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=16, shuffle=True, num_workers=0)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size=16, shuffle=False, num_workers=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccc8bc20-823a-4d7d-8ca9-b30f7e8900e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([784]) tensor(5)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torchvision.transforms.functional import to_pil_image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "for i, (x,y) in enumerate(train_set):\n",
    "    print(i, x.shape, y)\n",
    "    x = x.view(1,28,28)\n",
    "    img_pil = to_pil_image(x)\n",
    "    plt.imshow(img_pil, 'gray')\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b979a828-5645-483b-8af2-583d8fb2d326",
   "metadata": {},
   "source": [
    "Define the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2dced668-0156-41c5-b99e-e4de337b8239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "# import torch.nn.functional as F F.relu() for forward() \n",
    "\n",
    "#multi-layer perceptron (MLP) \n",
    "# MLPs cannot handle two or three-dimensional data\n",
    "class MNISTLogistic(nn.Module):\n",
    "    def __init__(self, N, N1, N2):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, N)  # pytorch finds the nn.Parameters inside this nn.Module\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(N, N1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(N1, N2)  # pytorch finds the nn.Parameters inside this nn.Module\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc4 = nn.Linear(N2, 10)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "\n",
    "    def forward(self, xb):\n",
    "        out = self.fc1(xb)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.relu3(out)\n",
    "        out = self.fc4(out)\n",
    "        out = self.softmax(out)\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0a9aa56-c7cc-4b33-bc02-89465b715123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out: torch.Tensor, yb: torch.Tensor) -> torch.Tensor:\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == yb).float().mean()\n",
    "\n",
    "def compute_val_accuracy(model, val_loader):\n",
    "    total_samples = 0\n",
    "    val_acc = 0\n",
    "    for i, batch in enumerate(val_loader):\n",
    "        x, y = batch\n",
    "        total_samples += y.shape[0]\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        pred = model(x)\n",
    "        val_acc += accuracy(pred, y)\n",
    "    return (val_acc/total_samples)\n",
    "\n",
    "def train(model, dataloader, loss_fn, opt, num_epoch, report_accuracy=True):\n",
    "    loss_history = []\n",
    "    train_history = []\n",
    "    val_history = []\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        model.train()\n",
    "\n",
    "        train_acc = 0\n",
    "        train_loss_accum = 0\n",
    "        total_samples = 0\n",
    "        \n",
    "        for i, batch in enumerate(dataloader):\n",
    "            x, y = batch\n",
    "            total_samples += y.shape[0]\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            opt.zero_grad()\n",
    "\n",
    "            pred = model(x)\n",
    "            loss_value = loss_fn(pred, y)\n",
    "            train_loss_accum += loss_value.item()\n",
    "\n",
    "            loss_value.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            if report_accuracy:\n",
    "                train_acc += accuracy(pred, y)\n",
    "\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_accuracy = compute_val_accuracy(model, val_loader)\n",
    "\n",
    "        ave_loss = train_loss_accum / i\n",
    "        train_accuracy = float(train_acc) / total_samples\n",
    "        \n",
    "        loss_history.append(float(ave_loss))  \n",
    "        train_history.append(float(train_accuracy))\n",
    "        val_history.append(float(val_accuracy))\n",
    "            \n",
    "            \n",
    "        print(\"Average loss: %f, Train accuracy: %f, Val accuracy: %f\" % (ave_loss, train_accuracy, val_accuracy))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93084cbf-dc5f-43e5-806b-258533881d35",
   "metadata": {},
   "source": [
    "The first layer has 784 neurons connected to 256 neurons, so 784*256 weighted connections plus 256 bias terms.\r\n",
    "\r\n",
    "The second layer has 650 neurons connected to2800 neurons, 6502800 weighted connections plus2800 bias terms.\r\n",
    "\r\n",
    "The third layer h28 100 neurons connected to 10 neuron28 100*10 weighted connections plus 10 bias terms.\r\n",
    "\r\n",
    "684⋅650+650285028002800+100⋅242,76222,360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f1e8926-ed3b-4f0b-8af2-de0fd50d3413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "<class 'torch.Tensor'> torch.Size([256, 784])\n",
      "<class 'torch.Tensor'> torch.Size([256])\n",
      "<class 'torch.Tensor'> torch.Size([128, 256])\n",
      "<class 'torch.Tensor'> torch.Size([128])\n",
      "<class 'torch.Tensor'> torch.Size([64, 128])\n",
      "<class 'torch.Tensor'> torch.Size([64])\n",
      "<class 'torch.Tensor'> torch.Size([10, 64])\n",
      "<class 'torch.Tensor'> torch.Size([10])\n",
      "The model has 242,762 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "# https://colab.research.google.com/github/bentrevett/pytorch-image-classification/blob/master/1_mlp.ipynb#scrollTo=gik6Q5ZB4O9q\n",
    "\n",
    "device = 'cpu' #'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "\n",
    "N = 256\n",
    "N1 = 128\n",
    "N2 = 64\n",
    "model = MNISTLogistic(N, N1, N2)\n",
    "\n",
    "for param in model.parameters():\n",
    "    print(type(param.data), param.size())\n",
    "\n",
    "count_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad) #to calculate the number of trainable parameters (weights and biases) in our model\n",
    "print(f'The model has {count_parameters:,} trainable parameters')\n",
    "\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4a9ff77d-7873-4e77-bfe6-1fc52b19f61b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m Initializes internal Module state, shared by both nn.Module and ScriptModule.\n",
       "\u001b[1;31mSource:\u001b[0m   \n",
       "    \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m784\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pytorch finds the nn.Parameters inside this nn.Module\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN2\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pytorch finds the nn.Parameters inside this nn.Module\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mN2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\oleg\\appdata\\local\\temp\\ipykernel_3728\\450453637.py\n",
       "\u001b[1;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.__init__??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9712b4d-6675-40e9-9a12-266de3139b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 1.610645, Train accuracy: 0.054247, Val accuracy: 0.057794\n",
      "Average loss: 1.531012, Train accuracy: 0.058344, Val accuracy: 0.058994\n",
      "Average loss: 1.514243, Train accuracy: 0.059371, Val accuracy: 0.059306\n",
      "Average loss: 1.504816, Train accuracy: 0.059896, Val accuracy: 0.060019\n",
      "Average loss: 1.498997, Train accuracy: 0.060253, Val accuracy: 0.060231\n",
      "CPU times: total: 3min 20s\n",
      "Wall time: 50 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train(model, train_loader, loss_fn, optimizer, num_epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "58ad2e9d-e5fd-448c-8d81-aeb40361e9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy1(y_pred, y):\n",
    "    top_pred = y_pred.argmax(1, keepdim=True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc\n",
    "\n",
    "def evaluate(model, iterator, criterion, device):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (x, y) in iterator:\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_pred = model(x)\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            acc = calculate_accuracy1(y_pred, y)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "    \n",
    "def train1(model, iterator, optimizer, criterion, device):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for (x, y) in iterator:\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(x)\n",
    "\n",
    "        loss = criterion(y_pred, y)\n",
    "\n",
    "        acc = calculate_accuracy1(y_pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c0bd43-1710-42c3-a790-78d2feb88d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss: 1.510365, Train accuracy: 0.950640, Val accuracy: 0.933900\n",
      "Average loss: 1.507473, Train accuracy: 0.953640, Val accuracy: 0.955800\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 5\n",
    "for epoch in range(num_epoch):\n",
    "    train_loss, train_acc = train1(model, train_loader, optimizer, loss_fn, device)\n",
    "    valid_loss, valid_acc = evaluate(model, val_loader, loss_fn, device)\n",
    "\n",
    "    print(\"Average loss: %f, Train accuracy: %f, Val accuracy: %f\" % (train_loss, train_acc, valid_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e0b2f3-2dfc-460c-8ed0-ada1c6b4ef71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
